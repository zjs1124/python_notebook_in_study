```python
from pyspark.sql import Window
from pyspark.sql.functions import *
from pyspark.sql.session import SparkSession

# 1、创建SparkSql执行环境
spark = SparkSession.builder.master("local").appName("sql").getOrCreate()

# 读取json格式的数据
# spark会自动解析json中的表结构
students_df = spark.read.format("json").load("../../data/students.json")

# collect_list:合并成列表，不去重
# collect_set：去重
# concat_ws:通过分隔符合并将列表合并成字符串
students_df \
    .groupby("clazz") \
    .agg(concat_ws("|", collect_list("name"))) \
    .show(truncate=False)

students_df \
    .groupby("clazz") \
    .agg(collect_set("gender")) \
    .show(truncate=False)
```